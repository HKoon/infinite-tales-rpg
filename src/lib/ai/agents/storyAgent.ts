import {stringifyPretty} from "$lib/util.svelte";
import type {LLM, LLMRequest} from "$lib/ai/llm";

export const storyStateForPrompt = {
    game: "Any Pen & Paper System e.g. Pathfinder, Call of Cthulhu, Star Wars, Fate Core, World of Darkness, GURPS, Mutants & Masterminds, Dungeons & Dragons",
    adventure_and_main_event: "Generate a random adventure with a random main story line. It does not have to be a quest, it can also be an event. It should be extraordinary and not cliche.",
    character_simple_description: "Generate a random character fitting the GAME system in ADVENTURE_AND_MAIN_EVENT, only provide a simple description and not every detail",
    general_image_prompt: "Create a general system prompt max 10 words for this adventure to add to every image that is generated by an ai. Format: {visualStyle} {genre} {artistReference}",
    theme: "THEME of the story telling, e.g. world the story is located in",
    tonality: "TONALITY of the story telling, writing style, must fit GAME system",
};

export class StoryAgent {

    llm: LLM;
    constructor(llm: LLM) {
        this.llm = llm;
    }

    async generateRandomStorySettings(overwrites = {}, characterDescription = undefined) : Promise<object> {
        const storyAgent = "You are RPG story agent, crafting captivating, limitless GAME experiences using BOOKS, THEME, TONALITY for CHARACTER.\n" +
            "Always respond with following JSON!\n" +
            stringifyPretty(storyStateForPrompt);

        const preset = {
            ...storyStateForPrompt,
            ...overwrites,
        }
        const request : LLMRequest = {
            userMessage : "Create a new randomized story considering the following settings: " + stringifyPretty(preset),
            historyMessages : [],
            systemInstruction : storyAgent,
        }
        if(characterDescription){
            request.historyMessages?.push({
                "role": "user",
                "content": "Character description: " + stringifyPretty(characterDescription)
            })
        }
        return await this.llm.generateContent(request);
    }

}
